{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dd0792b-9402-4849-bd42-fcc528acae2e",
   "metadata": {},
   "source": [
    "# Project: Building a RAG chatbot using python, Lancgchain and a pre-defined knowledge-base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e7b891-f6e0-49ff-9a95-01daa6bad7bf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 1. Retrieval-Augmented Generation (RAG)\n",
    "\n",
    "## What is RAG?\n",
    "One of the most powerful applications enabled by LLMs is sophisticated question-answering (Q&A) chatbots. These are applications that can answer questions about specific source information. These applications use a technique known as Retrieval Augmented Generation,\n",
    "\n",
    "**This tutorial will show how to build a simple Q&A application over a text data source**\n",
    "### Overview:\n",
    "A typical RAG application has two main components:\n",
    "\n",
    "### Indexing\n",
    "\n",
    "1. **Load**:\n",
    "   - First, we need to load our data. This is done using **Document Loaders**.\n",
    "   - Document loaders handle various file formats (e.g., text files, PDFs, web pages) and convert them into a standardized format for processing.\n",
    "\n",
    "2. **Split**:\n",
    "   - Text splitters break large documents into smaller chunks.\n",
    "   - This is useful for both indexing data and passing it into a model, as:\n",
    "     - Large chunks are harder to search over.\n",
    "     - They may not fit in a model's finite context window.\n",
    "\n",
    "3. **Store**:\n",
    "   - We need a place to store and index our splits so they can be searched over later.\n",
    "   - This is often done using a **VectorStore** and an **Embeddings model**.\n",
    "   - The embeddings model converts text into numerical vectors, and the vector store allows for efficient similarity search.\n",
    "\n",
    "### Retrieval and generation\n",
    "\n",
    "1. **Retrieve**:\n",
    "   - Given a user input, relevant splits are retrieved from storage using a **Retriever**.\n",
    "\n",
    "2. **Generate**:\n",
    "   - A **ChatModel** / **LLM** produces an answer using a prompt that includes both the question and the retrieved data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2ceeb5-484e-487f-a654-ccd62e0a9fcd",
   "metadata": {},
   "source": [
    "# 2. Building the Bot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9570348d-686b-4d58-bc19-347efcd842e3",
   "metadata": {},
   "source": [
    "### 1. Installing required packages\n",
    "\n",
    "for this tutorial we need the following python packages:\n",
    "\n",
    "\n",
    "1. **langchain-text-splitters**: A library for splitting text into chunks (e.g., for RAG pipelines).\n",
    "2. **langchain-community**: A collection of community-contributed tools and integrations for LangChain.\n",
    "3. **langchain[mistralai]**: A wrapper that connects our application with **open-source** and **free** **ChatModel**.\n",
    "4. **langchain-mistralai**: A library for integrating Mistral AI models with LangChain.\n",
    "5. **langchain-core**: Provides core functionalities for LangChain, including an in-memory vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a5aa660-f8ec-47b7-bf13-aaa3db8bd4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This command installs or upgrades specific Python packages using pip.\n",
    "# install: The pip subcommand used to install Python packages.\n",
    "\n",
    "# --quiet or -q: Suppresses unnecessary output during installation, making the process less verbose.\n",
    "# --upgrade or -U: Upgrades the specified packages to their latest versions if they are already installed.\n",
    "\n",
    "!pip install --quiet --upgrade langchain-text-splitters langchain-community \n",
    "!pip install -qU \"langchain[mistralai]\"\n",
    "!pip install -qU langchain-mistralai\n",
    "!pip install -qU langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7207f5-e14f-4f4a-a649-3d73b51bf31f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
